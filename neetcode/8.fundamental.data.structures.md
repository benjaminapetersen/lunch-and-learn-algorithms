# Top 8 Data Structures for Coding Interviews

- https://www.youtube.com/watch?v=uhYq27iSk9s

## Arrays

[1,3,4,7,8]

Arrays are stored in a continguous way.
In RAM, an array of values would be stored in a subset of that RAM in order.
This makes Arrays very efficient.  We can access any element in the array in constant time.

Operations:
- Insert End: Time Complexity O(1)
- Remove End: Time Complexity O(1)
- Insert Mid: Time Complexity O(n)
    - costly because we have to shift items out of the way to make room
- Remove Mid: Time Complexity O(n)
    - costly because we have to shift items back to fill the gap


## Linked Lists

Linked List are not stored in a contiguous way.
In RAM, they values are scattered.
Each value in the list contains a pointer to the next item.
Traversal is required to find items in the Linked List.

So long as we have a pointer to an element, we can easily update nodes.
There is no "shift" required like there is in an array

3 -> 6 -> 8 -> 9

Operations:

- Insert End: Time Complexity O(1)
- Remove End: Time Complexity O(1)
- Insert Mid: Time Complexity O(1)    
- Remove Mid: Time Complexity O(1)


## Hash Maps

Hash Maps are built on top of arrays.
Keys can be just about anything, since they are hashed into a value used to index into 
an underlying array.
The tradeoff is that insert & removal is ok, but there is no concept of an order.
The best feature of a Hash Map is the ability to search.  Search can be done in constant time.

Operations:
- Insert: Time Complexity O(1)
- Remove: Time Complexity O(1)
- Search: Time Complexity O(1)


## Queues

Queues are typically implemented in terms of a linked list.
We process queues in the same order that items are added.
Typically, we push to back, pop fromt front, making it a double-ended queue.

Queues are bi-directional, illustrated with arrows like this:

3 <=> 6 <=> 8 <=> 9

Operations:

- Push Front: Time Complexity O(1)
- Pop Front: Time Complexity O(1)
- Push Back: Time Complexity O(1)
- Pop Back: Time Complexity O(1)


## Binary Trees

Binary Trees are typically used as tree maps.
Each node typically has one value, but a Tree Map has a key-value pair, a key value mapped to a true value of the node.
TreeMaps are typically less efficient versions of a Hash Map.
But, a Binary Search tree has a certain property that makes them especially efficient.  This is because
nodes stored to the left imply a "less than" relationship to the parent node, and nodes stored to the right
imply a "greater than" relationship to the parent node.

The binary tree can be represented like this, where the arrows imply a single direction:


 6
 ├──> 3
 ├──> 8
      ├──> 9 

Operations:

- Insert: Time Complexity O(logn) (if the tree is balanced we get O(logn))
- Remove: Time Complexity O(logn) (if the tree is balanced we get O(logn))
- Search: Time Complexity O(logn) (if the tree is balanced we get O(logn))


## Trie / Prefix Tree

Each node typically represents a single character in the alphabet.
Each node can have upto 26 children.

Operations:

- Insert: Time Complexity O(n)
- Search: Time Complexity O(n)

What is the benefit?  
If we want to find ALL words starting with A, we can do by searching the graph.
Its great for an auto-complete type of functionality.

## Heaps

Heaps are typically visualized as trees.
Typically a min-heap or max-heap.
In a min-heap, the root value is the smallest in the tree, and all children are greater.
In a max-heap, the root value is the largest in the tree, and all children are smaller.
A heap will always be a complete tree: Every level will be full except the last level of the tree.
While typically `visualized` as a tree, they are actually implemented with arrays under the hood.
    Why?  Because finding nodes follow this pattern:
    [0] is empty.
    [1] is the first node
        Left child is found by `i * 2`
        Right child is found by `i * 2 + 1`
Main benefit of a heap is getting the minimum or maximum value in constant time O(1).
Pops and Inserts are blazing fast with O(logn).

[,3,6,8,9,...]

3
├── 6
├── 8
    ├── 9 

Operations:

- Insert: Time Complexity O(logn)
- Pop: Time Complexity O(logn)
- Min / Max: Time Complexity O(1)

## Graphs

Some of the hardest data structures to work with.
A Graph is just a node with edges that connect nodes together.
Linked Lists, Trees, Prefix Trees are also graphs.
A general graph can be more complicated as there are no restricted.
Directed graphs vs non-directed are two types of graphs.
Nodes can have any number of neighbors.
Sometimes an adjacency list is used to represent graphs.

Directed graph (with arrows representing direction).

6
├──> 7
├──> 4
├──> 3
├──> 8 
     ├──> 1

Node adjacency list representation (honoring the arrows which represent direction)

Node
7: []
4: []
6: [7,4,3,8]
3: []
8: [1]
1: []

Graphs are an especially complicated topic with many algorithms on top of them with varying time complexities.
